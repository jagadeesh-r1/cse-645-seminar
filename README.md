Reliable Reasoning Beyond Natural Language

Overview

This repository contains materials related to a seminar presentation on Reliable Reasoning Beyond Natural Language, inspired by the research paper by Nasim Borazjanizadeh and Steven T. Piantadosi from UC Berkeley. The presentation explores the limitations of Large Language Models (LLMs) in logical reasoning and introduces a NeuroSymbolic approach leveraging Prolog to enhance deductive reasoning.

Contents
	•	Presentation Slides: A detailed breakdown of the seminar, including key concepts and methodologies.
	•	Abstract: A concise summary of the research problem, proposed solution, and key outcomes.
	•	Discussion on LLMs: Introduction to Large Language Models, Transformer architecture, and their reasoning limitations.
	•	Prompt Engineering: Techniques like Chain-of-Thought (CoT) prompting to improve reasoning performance.
	•	Novel Approach: The integration of LLMs with Prolog for logical reasoning.
	•	Non-Linear Reasoning (NLR) Dataset: A dataset developed to benchmark reasoning abilities in LLMs.
	•	Performance Analysis: Results comparing traditional LLMs with the proposed NeuroSymbolic method.

Key Takeaways
	•	LLMs struggle with flexible, reliable deductive reasoning due to their sequential architecture and limited working memory.
	•	NeuroSymbolic Reasoning: Combining LLMs with Prolog enables better logical deductions.
	•	Chain-of-Thought Prompting: Helps break complex problems into intermediate steps, improving interpretability.
	•	New Dataset (NLR): Designed to test reasoning beyond memorization.
	•	Significant Performance Gains: The proposed approach outperforms even GPT-4 on specific reasoning benchmarks.
